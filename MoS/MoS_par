import numpy as np
from scipy.sparse import load_npz, issparse
from scipy.linalg import eigh
import os
from tqdm import tqdm
from multiprocessing import Pool, cpu_count, shared_memory
import gc
import h5py

# Configuración
BASE_PATH = "../Q_hat/Q_hat"
W_PATH = "../W/W_matrices/W_compressible_gamma1.354_Mach1.7_FULL.npz"
VARIABLES = ["density", "x_velocity", "y_velocity", "Temp"]
OUTPUT_DIR = "../SPOD_results"
BUFFER_SIZE = 2  # Ajustar según RAM

def load_frequency_data(freq_idx, Q_hat_files, spatial_dims):
    """Carga Q̂ para una frecuencia específica."""
    nx, ny = spatial_dims
    n_vars = len(VARIABLES)
    M = nx * ny * n_vars
    N = len(Q_hat_files)
    
    Q_k = np.zeros((M, N), dtype=np.complex128)
    for block_idx, block_files in enumerate(Q_hat_files):
        var_data = []
        for var_file in block_files:
            data = np.load(var_file)[:, :, freq_idx].flatten()
            var_data.append(data)
        Q_k[:, block_idx] = np.concatenate(var_data)
    return Q_k

def process_frequency(args):
    freq_idx, Q_hat_files, W_diag, spatial_dims = args
    try:
        Q_k = load_frequency_data(freq_idx, Q_hat_files, spatial_dims)
        W_Q = Q_k * W_diag.reshape(-1, 1)  # Broadcasting eficiente
        weighted_C = Q_k.conj().T @ W_Q
        eigvals, eigvecs = eigh(weighted_C)
        idx = np.argsort(eigvals)[::-1]
        Phi = Q_k @ eigvecs[:, idx] @ np.diag(1.0 / np.sqrt(eigvals[idx]))
        return freq_idx, eigvals[idx], Phi
    except Exception as e:
        print(f"Error en frecuencia {freq_idx}: {str(e)}")
        return freq_idx, None, None
    finally:
        gc.collect()

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. Cargar parámetros y W (solo una vez)
    sample = np.load(os.path.join(BASE_PATH, VARIABLES[0], "Q_hat_block01.npy"))
    nx, ny, N_FFT = sample.shape
    N_BLOCKS = len([f for f in os.listdir(os.path.join(BASE_PATH, VARIABLES[0])) 
                   if f.startswith("Q_hat_block")])
    M = nx * ny * len(VARIABLES)
    N = N_BLOCKS

    # Cargar W como vector diagonal (compartido entre procesos)
    W_sparse = load_npz(W_PATH)
    W_diag = W_sparse.diagonal().astype(np.float64, copy=False)  # Vector (M,)
    del W_sparse  # Liberar memoria sparse

    # 2. Estructura de archivos (solo paths)
    Q_hat_files = [
        [os.path.join(BASE_PATH, var, f"Q_hat_block{block_idx:02d}.npy") 
         for var in VARIABLES]
        for block_idx in range(1, N_BLOCKS + 1)
    ]

    # 3. Paralelización eficiente con chunks balanceados
    eigenvalues = np.zeros((N_FFT, N))
    freq_indices = list(range(N_FFT))
    
    with h5py.File(os.path.join(OUTPUT_DIR, "spod_modes.h5"), 'w') as hf:
        modes_dset = hf.create_dataset(
            "modes", 
            shape=(N_FFT, M, N), 
            dtype=np.complex128,
            chunks=(1, M, N),
            compression='gzip'
        )

        # Dividir frecuencias en chunks para balancear carga
        chunk_size = max(1, len(freq_indices) // (cpu_count() * 2))
        chunks = [
            freq_indices[i:i + chunk_size] 
            for i in range(0, len(freq_indices), chunk_size)
        ]

        for chunk in chunks:
            print(f"\nProcesando chunk: frecuencias {chunk[0]} a {chunk[-1]}")
            with Pool(processes=cpu_count()) as pool:
                args = [(f, Q_hat_files, W_diag, (nx, ny)) for f in chunk]
                
                for result in tqdm(
                    pool.imap_unordered(process_frequency, args),
                    total=len(chunk),
                    desc="Progreso"
                ):
                    freq_idx, eigvals, Phi = result
                    if eigvals is not None:
                        eigenvalues[freq_idx] = eigvals
                        modes_dset[freq_idx] = Phi

    np.save(os.path.join(OUTPUT_DIR, "spod_eigenvalues.npy"), eigenvalues)
    print("\n✅ ¡Proceso completado!")

if __name__ == "__main__":
    main()
