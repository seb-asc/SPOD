import numpy as np
from scipy.sparse import diags
import yt
from tqdm import tqdm
import os

# ========================================================================
# CONFIGURACIÓN GLOBAL (AJUSTAR SEGÚN TU CASO)
# ========================================================================
GAMMA = 1.354       # Ratio de calores específicos (γ) para tu fluido
MACH = 1.7          # Número de Mach característico
FIELDS = ["density", "x_velocity", "y_velocity", "Temp"]  # Campos AMReX
DATA_PATH = "../Simulations/S0.1_TEST"  # Ruta a tus archivos plt*

# ========================================================================
# FUNCIÓN PARA CARGAR PROMEDIOS DESDE AMReX
# ========================================================================
def load_mean_fields(snapshot_files, max_level=2):
    """Calcula campos medios temporales desde datos AMReX"""
    first_ds = yt.load(os.path.join(DATA_PATH, snapshot_files[0]))
    
    # Configuración de grilla
    ref = int(np.prod(first_ds.ref_factors[0:max_level]))
    low = first_ds.domain_left_edge
    dims = first_ds.domain_dimensions * ref
    nx, ny, _ = dims
    
    # Inicializar acumuladores
    accum = {field: np.zeros((nx, ny)) for field in FIELDS}
    cell_volumes = None
    
    # Procesar cada snapshot
    for file in tqdm(snapshot_files, desc="Calculando promedios"):
        ds = yt.load(os.path.join(DATA_PATH, file))
        cube = ds.covering_grid(max_level, left_edge=low, dims=dims, 
                              fields=[("boxlib", f) for f in FIELDS])
        
        # Acumular campos (solo plano xy, asumiendo 2D)
        for field in FIELDS:
            accum[field] += cube[("boxlib", field)].d[:, :, 0]
        
        # Obtener volúmenes (solo en primera iteración)
        if cell_volumes is None:
            if hasattr(cube, 'dx'):
                cell_volumes = cube.dx * cube.dy * cube.dz
            else:
                cell_volume = ds.domain_width / ds.domain_dimensions
                cell_volumes = np.prod(cell_volume) * np.ones((nx, ny))
    
    # Calcular promedios finales
    mean_fields = {
        "rho": accum["density"] / len(snapshot_files),
        "T": accum["Temp"] / len(snapshot_files),
        "vx": accum["x_velocity"] / len(snapshot_files),
        "vy": accum["y_velocity"] / len(snapshot_files)
    }
    
    return mean_fields, cell_volumes, dims

# ========================================================================
# CONSTRUCCIÓN DE LA MATRIZ W COMPRESIBLE
# ========================================================================
def build_compressible_W(mean_fields, cell_volumes, dims):
    """
    Construye la matriz W para norma de energía compresible
    
    Args:
        mean_fields: Diccionario con:
            - "rho": Array 2D de densidad media
            - "T": Array 2D de temperatura media
        cell_volumes: Array 2D con volúmenes de celda
        dims: Tupla (nx, ny, nz) con dimensiones espaciales
        
    Returns:
        W: Matriz dispersa CSR de tamaño (4*nx*ny, 4*nx*ny)
    """
    nx, ny = dims[0], dims[1]
    n_points = nx * ny
    
    # 1. Calcular pesos para cada componente
    rho_mean = mean_fields["rho"]
    T_mean = mean_fields["T"]
    
    # Pre-cálculo de términos comunes
    gamma_M2 = GAMMA * MACH**2
    common_denominator = GAMMA * (GAMMA - 1) * T_mean * MACH**2
    
    # Pesos individuales (flatten para eficiencia)
    w_rho = (T_mean / (gamma_M2 * rho_mean)).flatten()
    w_vel = rho_mean.flatten()
    w_temp = (rho_mean / common_denominator).flatten()
    
    # 2. Construir diagonal principal (orden: ρ, vx, vy, T para cada punto)
    diagonal = np.empty(4 * n_points)
    diagonal[0::4] = w_rho    # Densidad
    diagonal[1::4] = w_vel    # Velocidad x
    diagonal[2::4] = w_vel    # Velocidad y
    diagonal[3::4] = w_temp   # Temperatura
    
    # 3. Aplicar volúmenes de celda
    if isinstance(cell_volumes, np.ndarray):
        dV_flat = cell_volumes.flatten()
        diagonal *= np.repeat(dV_flat, 4)
    else:
        diagonal *= cell_volumes
    
    # 4. Crear matriz dispersa (formato CSR para operaciones eficientes)
    W = diags(diagonal, 0, format='csr')
    
    return W

# ========================================================================
# EJECUCIÓN PRINCIPAL
# ========================================================================
if __name__ == "__main__":
    # 1. Cargar lista de snapshots
    snapshot_files = [f for f in os.listdir(DATA_PATH) if f.startswith("plt")]
    snapshot_files = sorted(snapshot_files, key=lambda x: int(x.split("_")[-1]))
    
    # 2. Calcular campos medios (¡Hacer esto solo una vez!)
    print("\nCalculando campos medios...")
    mean_fields, cell_volumes, dims = load_mean_fields(snapshot_files)
    
    # 3. Construir matriz W
    print("\nConstruyendo matriz W...")
    W = build_compressible_W(mean_fields, cell_volumes, dims)
    
    # 4. Verificación
    print(f"\nMatriz W construida exitosamente!")
    print(f"Dimensiones: {W.shape}")
    print(f"Elementos no cero: {W.count_nonzero()}")
    print(f"Patrón de ejemplo (primeros 16 elementos diagonales):")
    print(W.diagonal()[:16].reshape(4, 4))  # Muestra pesos para primeros 4 puntos

    # 5. Guardar matriz (opcional)
    from scipy.sparse import save_npz
    save_npz("W_compressible_gamma1.354_Mach1.7.npz", W)